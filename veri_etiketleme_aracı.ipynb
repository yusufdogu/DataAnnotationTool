{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","mount_file_id":"1ebWMXOULnF7h-GHqBX5ojCvYgEzq22ZI","authorship_tag":"ABX9TyOrNNNvBXoN5fSaqTiDdHll"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install ultralytics ffmpeg-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"L3b-lEQ5LavB","executionInfo":{"status":"ok","timestamp":1739215837508,"user_tz":-180,"elapsed":65740,"user":{"displayName":"Yusuf Doğu","userId":"04280726024577573353"}},"outputId":"b4208a80-c186-4a37-d797-f92f82b7523a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.74-py3-none-any.whl.metadata (35 kB)\n","Collecting ffmpeg-python\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.74-py3-none-any.whl (914 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.7/914.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ffmpeg-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed ffmpeg-python-0.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.74 ultralytics-thop-2.0.14\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import logging\n","import ffmpeg\n","from ultralytics import YOLO"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mZa0rZH_Pndy","executionInfo":{"status":"ok","timestamp":1739215843557,"user_tz":-180,"elapsed":6038,"user":{"displayName":"Yusuf Doğu","userId":"04280726024577573353"}},"outputId":"9fb8a7bc-a4de-4247-b76a-fbd4f5f49384"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}]},{"cell_type":"code","source":["# Initialize logging\n","logging.basicConfig(level=logging.INFO)\n","\n","# Define function to check prerequisites\n","def check_prerequisites(output_text_file, frames_folder, annotations_folder):\n","    try:\n","        # Clear previous log file\n","        with open(output_text_file, \"w\", encoding=\"utf-8\"):\n","            pass\n","        logging.info(f\"Eski {output_text_file} dosyasının içeriği silindi.\")\n","    except Exception as e:\n","        logging.exception(f\"Log dosyası sıfırlanırken hata oluştu: {e}\")\n","\n","    prerequisites_action(frames_folder)\n","    prerequisites_action(annotations_folder)\n","\n","def prerequisites_action(action_parameter):\n","    if not os.path.exists(action_parameter):\n","        os.makedirs(action_parameter)\n","        logging.info(f\"{action_parameter} klasörü oluşturuldu.\")\n","    else:\n","        # Clean the folder by removing only files, keeping subdirectories\n","        for item in os.listdir(action_parameter):\n","            item_path = os.path.join(action_parameter, item)\n","            if os.path.isfile(item_path) or os.path.islink(item_path):\n","                try:\n","                    os.unlink(item_path)  # Remove files and symlinks\n","                    logging.info(f\"{item_path} silindi.\")\n","                except Exception as e:\n","                    logging.error(f\"Silme hatası: {item_path} - {e}\")\n","\n","def save_processed_frames(ret, frame_count, output_folder, frame):\n","    if ret:\n","        output_path = os.path.join(output_folder, f\"frame_{frame_count}.jpg\")\n","        cv2.imwrite(output_path, frame)\n","        logging.info(f\"Frame {frame_count} kaydedildi: {output_path}\")\n","    else:\n","        logging.warning(\"Kare bulunamadı veya kaydedilemedi.\")\n","\n","\n","def save_processed_txts(annotation_lines, annotations_folder, frame_count):\n","    # Ensure the annotations folder exists\n","    os.makedirs(annotations_folder, exist_ok=True)\n","\n","    # Construct the full path to save the file inside the annotations folder\n","    file_path = os.path.join(annotations_folder, f\"frame_{frame_count}.txt\")\n","\n","    # Write the annotations to the file\n","    with open(file_path, \"w\") as outfile:\n","        for line in annotation_lines:\n","            outfile.write(line + \"\\n\")\n","\n","    logging.info(f\"Etiket {frame_count} kaydedildi: {file_path}\")\n","\n","def save_detected_objects_txt(frame_count, frame, results_list, width, height):\n","    annotation_lines = []\n","    for obj in results_list:\n","        xmin, ymin, xmax, ymax = obj[0], obj[1], obj[2], obj[3]\n","        xmin = max(0, min(xmin, width))\n","        ymin = max(0, min(ymin, height))\n","        xmax = max(0, min(xmax, width))\n","        ymax = max(0, min(ymax, height))\n","        if xmin >= xmax or ymin >= ymax:\n","            continue\n","\n","        center_x = float((xmin + xmax) / 2) / width\n","        center_y = float((ymin + ymax) / 2) / height\n","        box_width = float(xmax - xmin) / width\n","        box_height = float(ymax - ymin) / height\n","\n","        yolo_annotations = f\"{obj[5]} {center_x} {center_y} {box_width} {box_height}\"\n","        annotation_lines.append(yolo_annotations)\n","\n","    save_processed_txts(annotation_lines,'/content/annotations',frame_count)\n"],"metadata":{"collapsed":true,"id":"0ewMuhNJKU77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#uploaded_video='/content/drive/MyDrive/pexels_araç_videoları/video_1.mp4'\n","#uploaded_video='/content/drive/MyDrive/pexels_araç_videoları/video_10.mp4'\n","uploaded_video='/content/drive/MyDrive/pexels_araç_videoları/video_11.mp4'\n"],"metadata":{"id":"26KbHS1ge316"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Check prerequisites\n","check_prerequisites('terminal.txt', 'frames', 'annotations')\n","\n","CONFIDENCE_THRESHOLD = 0.45\n","cap = cv2.VideoCapture(uploaded_video)\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","duration = total_frames / fps\n","\n","# Get video metadata\n","probe = ffmpeg.probe(uploaded_video)\n","video_info = next(stream for stream in probe[\"streams\"] if stream[\"codec_type\"] == \"video\")\n","width = int(video_info[\"width\"])\n","height = int(video_info[\"height\"])\n","\n","frame_interval = int(fps/2) if duration <= 20 else int(fps)\n","\n","# Load YOLO model\n","model = YOLO(\"/content/drive/MyDrive/best.pt\")\n","\n","frame_count = 0  # Initialize frame counter\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        logging.warning(\"Video bitti veya frame okunamadı.\")\n","        break\n","\n","    detections = model(frame, device='cuda')[0]\n","    results_list = []\n","\n","    for data in detections.boxes.data.tolist():\n","        confidence = data[4]\n","        if float(confidence) < CONFIDENCE_THRESHOLD:\n","            continue\n","        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n","        class_id = int(data[5])\n","        results_list.append([xmin, ymin, xmax, ymax, confidence, class_id])\n","\n","    if frame_count % frame_interval == 0:\n","      save_processed_frames(ret, frame_count, 'frames', frame)\n","      save_detected_objects_txt(frame_count, frame, results_list, width, height)\n","\n","    frame_count += 1\n","\n","logging.info(\"Görüntü işleme sonlandı.\")\n","cap.release()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"cvCjcC-8PavO","executionInfo":{"status":"ok","timestamp":1739220259409,"user_tz":-180,"elapsed":76858,"user":{"displayName":"Yusuf Doğu","userId":"04280726024577573353"}},"outputId":"750af8f5-17b7-48dd-8383-14a77412d5f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 31 Arabas, 8 Insans, 64.1ms\n","Speed: 2.8ms preprocess, 64.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 8 Insans, 36.1ms\n","Speed: 2.7ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 7 Insans, 35.7ms\n","Speed: 2.6ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 7 Insans, 36.4ms\n","Speed: 2.4ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 9 Insans, 36.2ms\n","Speed: 2.5ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 9 Insans, 35.8ms\n","Speed: 2.3ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 10 Insans, 35.8ms\n","Speed: 2.2ms preprocess, 35.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 8 Insans, 34.3ms\n","Speed: 2.3ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 10 Insans, 34.3ms\n","Speed: 2.4ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 9 Insans, 36.0ms\n","Speed: 2.6ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 8 Insans, 35.7ms\n","Speed: 2.3ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 9 Insans, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 9 Insans, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 11 Insans, 36.8ms\n","Speed: 2.2ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 13 Insans, 35.7ms\n","Speed: 2.7ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 14 Insans, 34.3ms\n","Speed: 2.3ms preprocess, 34.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 12 Insans, 34.8ms\n","Speed: 2.5ms preprocess, 34.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 35.7ms\n","Speed: 3.5ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 12 Insans, 34.7ms\n","Speed: 2.6ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 36.0ms\n","Speed: 2.4ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 11 Insans, 36.3ms\n","Speed: 2.3ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 33.8ms\n","Speed: 3.2ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 34.4ms\n","Speed: 2.2ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 36.0ms\n","Speed: 2.5ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 36.7ms\n","Speed: 2.4ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 34.7ms\n","Speed: 2.2ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 12 Insans, 35.1ms\n","Speed: 2.4ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 37.0ms\n","Speed: 2.2ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 34.7ms\n","Speed: 3.4ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 12 Insans, 35.9ms\n","Speed: 2.3ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 11 Insans, 33.1ms\n","Speed: 2.3ms preprocess, 33.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 13 Insans, 34.8ms\n","Speed: 2.3ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 13 Insans, 35.7ms\n","Speed: 3.3ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 10 Insans, 36.2ms\n","Speed: 2.6ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 12 Insans, 34.6ms\n","Speed: 3.4ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 12 Insans, 36.1ms\n","Speed: 2.3ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 9 Insans, 36.7ms\n","Speed: 2.4ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 9 Insans, 34.7ms\n","Speed: 2.3ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 10 Insans, 34.5ms\n","Speed: 2.6ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 9 Insans, 35.8ms\n","Speed: 2.3ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 9 Insans, 34.6ms\n","Speed: 2.5ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 9 Insans, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 9 Insans, 36.4ms\n","Speed: 2.4ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 12 Insans, 36.2ms\n","Speed: 2.5ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 10 Insans, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 10 Insans, 37.0ms\n","Speed: 3.0ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 10 Insans, 35.6ms\n","Speed: 2.4ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 12 Insans, 34.9ms\n","Speed: 2.3ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 11 Insans, 35.6ms\n","Speed: 3.5ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 14 Insans, 36.1ms\n","Speed: 2.4ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 12 Insans, 35.4ms\n","Speed: 2.3ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 12 Insans, 36.3ms\n","Speed: 2.5ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 13 Insans, 36.9ms\n","Speed: 2.6ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 12 Insans, 35.3ms\n","Speed: 2.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 12 Insans, 35.6ms\n","Speed: 2.4ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 12 Insans, 37.7ms\n","Speed: 2.3ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 12 Insans, 35.0ms\n","Speed: 2.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 10 Insans, 34.5ms\n","Speed: 2.5ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 11 Insans, 35.6ms\n","Speed: 2.2ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 12 Insans, 33.6ms\n","Speed: 2.6ms preprocess, 33.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 11 Insans, 35.4ms\n","Speed: 2.9ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 11 Insans, 38.0ms\n","Speed: 2.5ms preprocess, 38.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 9 Insans, 35.2ms\n","Speed: 2.3ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 11 Insans, 35.8ms\n","Speed: 2.4ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 36.3ms\n","Speed: 2.4ms preprocess, 36.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 35.7ms\n","Speed: 2.3ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 35.1ms\n","Speed: 2.4ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 10 Insans, 36.2ms\n","Speed: 2.5ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 10 Insans, 35.7ms\n","Speed: 2.1ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 10 Insans, 34.7ms\n","Speed: 3.3ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 9 Insans, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 35.8ms\n","Speed: 2.3ms preprocess, 35.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 10 Insans, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 9 Insans, 36.0ms\n","Speed: 2.4ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 9 Insans, 36.6ms\n","Speed: 2.3ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 10 Insans, 34.9ms\n","Speed: 2.6ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 10 Insans, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 9 Insans, 36.6ms\n","Speed: 2.3ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 11 Insans, 34.8ms\n","Speed: 3.2ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 10 Insans, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 10 Insans, 36.4ms\n","Speed: 3.0ms preprocess, 36.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 11 Insans, 34.6ms\n","Speed: 2.7ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 11 Insans, 37.1ms\n","Speed: 2.5ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 12 Insans, 33.8ms\n","Speed: 3.4ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 9 Insans, 35.2ms\n","Speed: 2.8ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 8 Insans, 37.0ms\n","Speed: 2.4ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 8 Insans, 33.7ms\n","Speed: 3.4ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 10 Insans, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 9 Insans, 33.7ms\n","Speed: 3.3ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 8 Insans, 35.4ms\n","Speed: 2.4ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 9 Insans, 37.2ms\n","Speed: 2.4ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 8 Insans, 34.6ms\n","Speed: 3.2ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 8 Insans, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 7 Insans, 36.5ms\n","Speed: 2.3ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 8 Insans, 34.6ms\n","Speed: 2.3ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 11 Insans, 35.3ms\n","Speed: 2.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 9 Insans, 37.4ms\n","Speed: 2.5ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 9 Insans, 35.4ms\n","Speed: 3.4ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 10 Insans, 35.3ms\n","Speed: 2.2ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 11 Insans, 37.0ms\n","Speed: 3.3ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 11 Insans, 34.6ms\n","Speed: 3.2ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 10 Insans, 36.0ms\n","Speed: 2.4ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 10 Insans, 36.1ms\n","Speed: 2.4ms preprocess, 36.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 34.5ms\n","Speed: 3.3ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 10 Insans, 36.1ms\n","Speed: 2.3ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 10 Insans, 36.2ms\n","Speed: 2.7ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 9 Insans, 35.2ms\n","Speed: 2.4ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 10 Insans, 36.7ms\n","Speed: 2.3ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 34.9ms\n","Speed: 3.7ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 9 Insans, 36.3ms\n","Speed: 3.2ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 9 Insans, 34.4ms\n","Speed: 2.7ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 10 Insans, 34.4ms\n","Speed: 3.2ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 10 Insans, 36.7ms\n","Speed: 2.6ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 36.1ms\n","Speed: 2.8ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 12 Insans, 35.1ms\n","Speed: 2.4ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 12 Insans, 36.7ms\n","Speed: 2.5ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 14 Insans, 34.1ms\n","Speed: 3.3ms preprocess, 34.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 13 Insans, 37.7ms\n","Speed: 2.3ms preprocess, 37.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 35.8ms\n","Speed: 2.4ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 11 Insans, 35.2ms\n","Speed: 2.1ms preprocess, 35.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 12 Insans, 37.6ms\n","Speed: 2.3ms preprocess, 37.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 12 Insans, 35.3ms\n","Speed: 2.3ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 12 Insans, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 12 Insans, 37.1ms\n","Speed: 2.6ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 11 Insans, 36.8ms\n","Speed: 2.2ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 10 Insans, 35.1ms\n","Speed: 2.3ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 12 Insans, 36.8ms\n","Speed: 2.3ms preprocess, 36.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 13 Insans, 36.4ms\n","Speed: 2.2ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 12 Insans, 35.1ms\n","Speed: 2.7ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 11 Insans, 35.4ms\n","Speed: 2.1ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 12 Insans, 37.0ms\n","Speed: 2.4ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 9 Insans, 35.6ms\n","Speed: 2.4ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 10 Insans, 35.8ms\n","Speed: 2.4ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 36.4ms\n","Speed: 2.3ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 13 Insans, 35.7ms\n","Speed: 2.1ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 13 Insans, 35.1ms\n","Speed: 2.6ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 35.8ms\n","Speed: 2.6ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 36.7ms\n","Speed: 2.2ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 10 Insans, 34.5ms\n","Speed: 2.5ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 35.1ms\n","Speed: 2.5ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 9 Insans, 37.1ms\n","Speed: 2.4ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 8 Insans, 35.2ms\n","Speed: 3.3ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 9 Insans, 36.4ms\n","Speed: 2.3ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 9 Insans, 35.8ms\n","Speed: 2.2ms preprocess, 35.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 11 Insans, 37.1ms\n","Speed: 2.1ms preprocess, 37.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 10 Insans, 33.3ms\n","Speed: 2.4ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 11 Insans, 37.1ms\n","Speed: 2.6ms preprocess, 37.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 11 Insans, 35.0ms\n","Speed: 2.1ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 11 Insans, 35.3ms\n","Speed: 2.2ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 11 Insans, 36.4ms\n","Speed: 2.4ms preprocess, 36.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 10 Insans, 36.2ms\n","Speed: 2.4ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 9 Insans, 35.1ms\n","Speed: 2.3ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 9 Insans, 36.5ms\n","Speed: 2.2ms preprocess, 36.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 9 Insans, 35.5ms\n","Speed: 2.3ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 8 Insans, 35.1ms\n","Speed: 2.3ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 10 Insans, 35.5ms\n","Speed: 2.2ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 9 Insans, 36.6ms\n","Speed: 3.4ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 9 Insans, 35.5ms\n","Speed: 2.2ms preprocess, 35.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 9 Insans, 35.5ms\n","Speed: 2.1ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 9 Insans, 36.4ms\n","Speed: 2.1ms preprocess, 36.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 10 Insans, 36.6ms\n","Speed: 2.4ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 11 Insans, 35.2ms\n","Speed: 2.3ms preprocess, 35.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 10 Insans, 36.0ms\n","Speed: 2.3ms preprocess, 36.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 13 Insans, 37.8ms\n","Speed: 2.3ms preprocess, 37.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 13 Insans, 35.5ms\n","Speed: 2.5ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 11 Insans, 35.2ms\n","Speed: 2.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 13 Insans, 37.0ms\n","Speed: 2.4ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 15 Insans, 34.9ms\n","Speed: 2.5ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 14 Insans, 34.7ms\n","Speed: 2.3ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 14 Insans, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 12 Insans, 37.8ms\n","Speed: 2.1ms preprocess, 37.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 12 Insans, 35.9ms\n","Speed: 2.4ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 12 Insans, 35.1ms\n","Speed: 3.1ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 13 Insans, 37.7ms\n","Speed: 2.2ms preprocess, 37.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 14 Insans, 34.1ms\n","Speed: 2.3ms preprocess, 34.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 15 Insans, 37.2ms\n","Speed: 2.5ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 14 Insans, 36.6ms\n","Speed: 2.2ms preprocess, 36.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 14 Insans, 35.4ms\n","Speed: 2.1ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 13 Insans, 37.1ms\n","Speed: 3.4ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 12 Insans, 35.6ms\n","Speed: 2.3ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 14 Insans, 35.0ms\n","Speed: 2.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 15 Insans, 36.4ms\n","Speed: 2.3ms preprocess, 36.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 13 Insans, 36.4ms\n","Speed: 2.5ms preprocess, 36.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 12 Insans, 35.7ms\n","Speed: 2.2ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 15 Insans, 35.5ms\n","Speed: 2.3ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 14 Insans, 38.2ms\n","Speed: 2.6ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 15 Insans, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 14 Insans, 35.9ms\n","Speed: 2.3ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 14 Insans, 37.0ms\n","Speed: 2.3ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 13 Insans, 35.7ms\n","Speed: 2.2ms preprocess, 35.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 11 Insans, 35.7ms\n","Speed: 2.5ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 14 Insans, 37.0ms\n","Speed: 2.0ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 14 Insans, 37.3ms\n","Speed: 2.3ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 9 Insans, 35.5ms\n","Speed: 2.2ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 12 Insans, 37.8ms\n","Speed: 2.4ms preprocess, 37.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 13 Insans, 36.8ms\n","Speed: 2.2ms preprocess, 36.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 11 Insans, 36.2ms\n","Speed: 2.0ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 12 Insans, 37.1ms\n","Speed: 2.3ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 12 Insans, 36.8ms\n","Speed: 2.5ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 13 Insans, 35.1ms\n","Speed: 2.4ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 14 Insans, 36.4ms\n","Speed: 2.2ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 12 Insans, 37.9ms\n","Speed: 2.4ms preprocess, 37.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 12 Insans, 34.7ms\n","Speed: 2.4ms preprocess, 34.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 14 Insans, 32.8ms\n","Speed: 2.4ms preprocess, 32.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 12 Insans, 35.3ms\n","Speed: 3.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 11 Insans, 35.9ms\n","Speed: 2.4ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 12 Insans, 38.2ms\n","Speed: 2.7ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 13 Insans, 35.2ms\n","Speed: 2.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 12 Insans, 35.6ms\n","Speed: 2.2ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 12 Insans, 36.6ms\n","Speed: 3.4ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 35.8ms\n","Speed: 2.6ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 12 Insans, 35.5ms\n","Speed: 2.2ms preprocess, 35.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 13 Insans, 37.1ms\n","Speed: 3.2ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 14 Insans, 35.6ms\n","Speed: 3.4ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 13 Insans, 35.3ms\n","Speed: 2.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 11 Insans, 37.9ms\n","Speed: 3.4ms preprocess, 37.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 13 Insans, 34.7ms\n","Speed: 2.2ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 12 Insans, 35.7ms\n","Speed: 2.5ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 12 Insans, 38.4ms\n","Speed: 2.2ms preprocess, 38.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 12 Insans, 35.3ms\n","Speed: 2.2ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 10 Insans, 35.2ms\n","Speed: 2.5ms preprocess, 35.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 9 Insans, 37.0ms\n","Speed: 2.3ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 10 Insans, 35.8ms\n","Speed: 2.3ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 12 Insans, 35.5ms\n","Speed: 2.3ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 12 Insans, 35.8ms\n","Speed: 2.3ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 10 Insans, 37.9ms\n","Speed: 2.3ms preprocess, 37.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 13 Insans, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 11 Insans, 36.0ms\n","Speed: 2.4ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 12 Insans, 37.4ms\n","Speed: 2.2ms preprocess, 37.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 13 Insans, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 14 Insans, 36.8ms\n","Speed: 2.4ms preprocess, 36.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 13 Insans, 37.3ms\n","Speed: 2.2ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 12 Insans, 33.7ms\n","Speed: 2.3ms preprocess, 33.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 12 Insans, 36.4ms\n","Speed: 2.2ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 35.7ms\n","Speed: 2.6ms preprocess, 35.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 36.7ms\n","Speed: 2.1ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 11 Insans, 37.0ms\n","Speed: 2.5ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 10 Insans, 34.5ms\n","Speed: 2.3ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 35.4ms\n","Speed: 2.4ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 11 Insans, 37.7ms\n","Speed: 2.4ms preprocess, 37.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 11 Insans, 35.5ms\n","Speed: 2.4ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 12 Insans, 35.1ms\n","Speed: 2.4ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 11 Insans, 36.7ms\n","Speed: 2.0ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 11 Insans, 36.9ms\n","Speed: 2.3ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 15 Insans, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 13 Insans, 35.9ms\n","Speed: 2.4ms preprocess, 35.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 12 Insans, 37.9ms\n","Speed: 2.6ms preprocess, 37.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 12 Insans, 35.3ms\n","Speed: 2.4ms preprocess, 35.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 11 Insans, 36.2ms\n","Speed: 2.4ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 11 Insans, 37.0ms\n","Speed: 2.5ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 11 Insans, 35.5ms\n","Speed: 2.3ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 11 Insans, 35.5ms\n","Speed: 2.4ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 11 Insans, 36.4ms\n","Speed: 2.5ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 11 Insans, 36.4ms\n","Speed: 2.5ms preprocess, 36.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 14 Insans, 35.2ms\n","Speed: 2.5ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 13 Insans, 36.1ms\n","Speed: 2.2ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 13 Insans, 37.7ms\n","Speed: 2.5ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 34.9ms\n","Speed: 3.6ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 36.0ms\n","Speed: 2.5ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 37.2ms\n","Speed: 2.3ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 10 Insans, 35.8ms\n","Speed: 2.6ms preprocess, 35.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 14 Insans, 33.0ms\n","Speed: 2.5ms preprocess, 33.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 35.6ms\n","Speed: 2.3ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 13 Insans, 37.7ms\n","Speed: 2.3ms preprocess, 37.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 11 Insans, 35.5ms\n","Speed: 2.5ms preprocess, 35.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 12 Insans, 37.1ms\n","Speed: 2.5ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 11 Insans, 36.1ms\n","Speed: 2.7ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 14 Insans, 34.9ms\n","Speed: 2.1ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 13 Insans, 35.8ms\n","Speed: 2.4ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 13 Insans, 37.7ms\n","Speed: 2.7ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 12 Insans, 35.6ms\n","Speed: 2.3ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 14 Insans, 36.5ms\n","Speed: 2.2ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 13 Insans, 36.7ms\n","Speed: 2.5ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 35.8ms\n","Speed: 3.0ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 14 Insans, 37.4ms\n","Speed: 2.4ms preprocess, 37.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 36.8ms\n","Speed: 2.3ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 13 Insans, 35.4ms\n","Speed: 2.3ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 13 Insans, 36.4ms\n","Speed: 2.6ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 38.0ms\n","Speed: 2.2ms preprocess, 38.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 11 Insans, 35.6ms\n","Speed: 2.3ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 9 Insans, 36.8ms\n","Speed: 2.3ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 11 Insans, 36.1ms\n","Speed: 2.2ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 13 Insans, 35.4ms\n","Speed: 2.3ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 14 Insans, 36.0ms\n","Speed: 2.4ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 14 Insans, 38.5ms\n","Speed: 2.4ms preprocess, 38.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 13 Insans, 35.7ms\n","Speed: 2.2ms preprocess, 35.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 13 Insans, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 13 Insans, 38.2ms\n","Speed: 2.4ms preprocess, 38.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 12 Insans, 33.5ms\n","Speed: 3.2ms preprocess, 33.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 10 Insans, 36.4ms\n","Speed: 2.3ms preprocess, 36.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 11 Insans, 35.8ms\n","Speed: 2.5ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 12 Insans, 36.5ms\n","Speed: 2.5ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 10 Insans, 37.9ms\n","Speed: 2.2ms preprocess, 37.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 8 Insans, 35.6ms\n","Speed: 2.3ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 9 Insans, 35.8ms\n","Speed: 3.3ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 10 Insans, 36.8ms\n","Speed: 2.4ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 10 Insans, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 11 Insans, 36.1ms\n","Speed: 2.9ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 12 Insans, 36.3ms\n","Speed: 3.3ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 11 Insans, 35.6ms\n","Speed: 2.3ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 9 Insans, 37.1ms\n","Speed: 2.4ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 10 Insans, 36.8ms\n","Speed: 3.3ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 4 Insans, 35.1ms\n","Speed: 2.1ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 5 Insans, 36.8ms\n","Speed: 2.3ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 5 Insans, 36.8ms\n","Speed: 2.2ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 5 Insans, 35.5ms\n","Speed: 2.1ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 4 Insans, 36.4ms\n","Speed: 2.1ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 4 Insans, 37.2ms\n","Speed: 2.4ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 3 Insans, 35.9ms\n","Speed: 2.3ms preprocess, 35.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 4 Insans, 36.6ms\n","Speed: 2.4ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 5 Insans, 38.1ms\n","Speed: 2.7ms preprocess, 38.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 4 Insans, 35.1ms\n","Speed: 2.8ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 6 Insans, 36.0ms\n","Speed: 3.1ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 5 Insans, 37.3ms\n","Speed: 2.2ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 6 Insans, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 5 Insans, 36.0ms\n","Speed: 3.4ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 5 Insans, 36.9ms\n","Speed: 2.5ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 4 Insans, 33.7ms\n","Speed: 2.4ms preprocess, 33.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 4 Insans, 36.7ms\n","Speed: 2.2ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 4 Insans, 35.6ms\n","Speed: 2.6ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 4 Insans, 1 Motor, 36.5ms\n","Speed: 2.2ms preprocess, 36.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 3 Insans, 1 Motor, 37.0ms\n","Speed: 2.4ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 3 Insans, 1 Motor, 35.2ms\n","Speed: 3.2ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 3 Insans, 1 Motor, 38.2ms\n","Speed: 2.6ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 2 Insans, 1 Motor, 36.3ms\n","Speed: 2.7ms preprocess, 36.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 3 Insans, 1 Motor, 36.8ms\n","Speed: 2.8ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 3 Insans, 1 Motor, 36.3ms\n","Speed: 2.4ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 3 Insans, 1 Motor, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 3 Insans, 1 Motor, 37.0ms\n","Speed: 2.5ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 3 Insans, 1 Motor, 34.6ms\n","Speed: 2.9ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 3 Insans, 1 Motor, 35.5ms\n","Speed: 2.5ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 3 Insans, 1 Motor, 38.1ms\n","Speed: 2.6ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 2 Insans, 1 Motor, 34.9ms\n","Speed: 2.3ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 4 Insans, 35.2ms\n","Speed: 3.5ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 2 Insans, 1 Motor, 38.1ms\n","Speed: 2.2ms preprocess, 38.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 2 Insans, 1 Motor, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 3 Insans, 1 Motor, 37.7ms\n","Speed: 2.5ms preprocess, 37.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 1 Insan, 1 Motor, 36.3ms\n","Speed: 2.4ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 3 Insans, 35.6ms\n","Speed: 2.6ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 2 Insans, 1 Motor, 37.5ms\n","Speed: 2.6ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 2 Insans, 1 Motor, 35.9ms\n","Speed: 2.7ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 4 Insans, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 4 Insans, 37.3ms\n","Speed: 2.6ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 4 Insans, 35.3ms\n","Speed: 2.5ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 4 Insans, 36.1ms\n","Speed: 2.8ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 3 Insans, 37.3ms\n","Speed: 2.3ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 3 Insans, 34.3ms\n","Speed: 2.6ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 2 Insans, 1 Motor, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 2 Insans, 1 Motor, 36.0ms\n","Speed: 3.4ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 3 Insans, 36.6ms\n","Speed: 2.5ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 3 Insans, 1 Motor, 35.4ms\n","Speed: 2.7ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 2 Insans, 1 Motor, 36.1ms\n","Speed: 3.4ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 3 Insans, 35.8ms\n","Speed: 3.5ms preprocess, 35.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 3 Insans, 35.4ms\n","Speed: 3.5ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 4 Insans, 38.5ms\n","Speed: 3.4ms preprocess, 38.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 5 Insans, 35.8ms\n","Speed: 2.4ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 5 Insans, 36.7ms\n","Speed: 2.7ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 4 Insans, 36.2ms\n","Speed: 2.4ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 4 Insans, 35.6ms\n","Speed: 4.1ms preprocess, 35.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 4 Insans, 37.7ms\n","Speed: 2.8ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 4 Insans, 34.6ms\n","Speed: 3.5ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 5 Insans, 35.5ms\n","Speed: 3.3ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 5 Insans, 37.4ms\n","Speed: 2.6ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 5 Insans, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 4 Insans, 36.7ms\n","Speed: 2.7ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 3 Insans, 34.9ms\n","Speed: 3.4ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 4 Insans, 35.0ms\n","Speed: 2.6ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 6 Insans, 36.5ms\n","Speed: 2.9ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 5 Insans, 35.9ms\n","Speed: 3.2ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 6 Insans, 36.0ms\n","Speed: 2.7ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 5 Insans, 38.1ms\n","Speed: 2.2ms preprocess, 38.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 5 Insans, 1 Otobus, 35.0ms\n","Speed: 2.3ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 5 Insans, 1 Otobus, 36.0ms\n","Speed: 2.4ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 5 Insans, 1 Otobus, 38.0ms\n","Speed: 2.6ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 5 Insans, 1 Otobus, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 4 Insans, 1 Otobus, 33.4ms\n","Speed: 2.7ms preprocess, 33.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 4 Insans, 1 Otobus, 35.7ms\n","Speed: 2.7ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 4 Insans, 1 Otobus, 37.1ms\n","Speed: 2.3ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 4 Insans, 1 Otobus, 36.8ms\n","Speed: 3.2ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 5 Insans, 1 Otobus, 35.5ms\n","Speed: 2.1ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 Arabas, 5 Insans, 1 Otobus, 36.5ms\n","Speed: 2.6ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 Arabas, 4 Insans, 1 Otobus, 37.2ms\n","Speed: 2.3ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 3 Insans, 1 Otobus, 35.0ms\n","Speed: 2.5ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 6 Insans, 1 Otobus, 36.7ms\n","Speed: 2.5ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 6 Insans, 37.1ms\n","Speed: 2.3ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 6 Insans, 34.7ms\n","Speed: 3.2ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 6 Insans, 36.5ms\n","Speed: 2.6ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 Arabas, 6 Insans, 1 Otobus, 37.2ms\n","Speed: 3.4ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 6 Insans, 1 Otobus, 35.8ms\n","Speed: 2.3ms preprocess, 35.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 6 Insans, 2 Otobuss, 37.7ms\n","Speed: 2.7ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 6 Insans, 35.5ms\n","Speed: 2.4ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 6 Insans, 2 Otobuss, 35.0ms\n","Speed: 2.7ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 6 Insans, 1 Otobus, 36.8ms\n","Speed: 2.3ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 7 Insans, 2 Otobuss, 37.6ms\n","Speed: 2.8ms preprocess, 37.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 7 Insans, 2 Otobuss, 35.8ms\n","Speed: 2.3ms preprocess, 35.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 6 Insans, 2 Otobuss, 37.0ms\n","Speed: 3.5ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 6 Insans, 35.5ms\n","Speed: 2.7ms preprocess, 35.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 6 Insans, 1 Otobus, 35.1ms\n","Speed: 2.3ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 Arabas, 5 Insans, 1 Otobus, 36.1ms\n","Speed: 2.7ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 Arabas, 6 Insans, 1 Otobus, 36.9ms\n","Speed: 3.4ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 Arabas, 6 Insans, 1 Otobus, 35.8ms\n","Speed: 2.3ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 7 Insans, 1 Otobus, 36.7ms\n","Speed: 2.9ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 5 Insans, 1 Otobus, 35.7ms\n","Speed: 2.9ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 7 Insans, 1 Otobus, 35.5ms\n","Speed: 2.4ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 6 Insans, 1 Otobus, 33.1ms\n","Speed: 3.1ms preprocess, 33.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 Arabas, 6 Insans, 2 Otobuss, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 Arabas, 6 Insans, 1 Otobus, 36.4ms\n","Speed: 2.7ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 Arabas, 7 Insans, 1 Otobus, 37.8ms\n","Speed: 2.3ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 Arabas, 7 Insans, 1 Otobus, 34.9ms\n","Speed: 2.7ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 Arabas, 5 Insans, 2 Otobuss, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 Arabas, 5 Insans, 2 Otobuss, 36.2ms\n","Speed: 2.6ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 4 Insans, 2 Otobuss, 35.6ms\n","Speed: 2.2ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 Arabas, 4 Insans, 1 Otobus, 36.8ms\n","Speed: 2.2ms preprocess, 36.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 3 Insans, 2 Otobuss, 37.0ms\n","Speed: 2.4ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 Arabas, 5 Insans, 1 Otobus, 35.4ms\n","Speed: 2.4ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 Arabas, 6 Insans, 1 Otobus, 36.4ms\n","Speed: 2.9ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 5 Insans, 1 Otobus, 38.2ms\n","Speed: 2.5ms preprocess, 38.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 5 Insans, 1 Otobus, 35.8ms\n","Speed: 2.5ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 Arabas, 4 Insans, 1 Otobus, 37.1ms\n","Speed: 2.6ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 Arabas, 6 Insans, 1 Otobus, 36.8ms\n","Speed: 2.6ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 6 Insans, 2 Otobuss, 35.0ms\n","Speed: 2.7ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 Arabas, 6 Insans, 2 Otobuss, 37.5ms\n","Speed: 2.2ms preprocess, 37.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 5 Insans, 2 Otobuss, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 Arabas, 6 Insans, 2 Otobuss, 35.5ms\n","Speed: 2.8ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 5 Insans, 1 Otobus, 36.7ms\n","Speed: 2.4ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 5 Insans, 1 Otobus, 35.9ms\n","Speed: 3.2ms preprocess, 35.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 Arabas, 6 Insans, 2 Otobuss, 35.7ms\n","Speed: 3.3ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 Arabas, 5 Insans, 1 Otobus, 37.5ms\n","Speed: 3.2ms preprocess, 37.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 6 Insans, 2 Otobuss, 34.7ms\n","Speed: 2.4ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 Arabas, 6 Insans, 2 Otobuss, 35.6ms\n","Speed: 2.9ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 6 Insans, 2 Otobuss, 37.6ms\n","Speed: 2.3ms preprocess, 37.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 6 Insans, 2 Otobuss, 34.8ms\n","Speed: 2.4ms preprocess, 34.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 6 Insans, 1 Otobus, 36.6ms\n","Speed: 2.2ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 Arabas, 4 Insans, 1 Otobus, 34.2ms\n","Speed: 2.3ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 5 Insans, 1 Otobus, 36.7ms\n","Speed: 2.2ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 6 Insans, 1 Otobus, 38.0ms\n","Speed: 2.9ms preprocess, 38.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 7 Insans, 1 Otobus, 35.4ms\n","Speed: 2.4ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 6 Insans, 35.6ms\n","Speed: 2.7ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 6 Insans, 1 Otobus, 37.4ms\n","Speed: 2.4ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 7 Insans, 2 Otobuss, 35.5ms\n","Speed: 2.3ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 6 Insans, 2 Otobuss, 36.4ms\n","Speed: 2.3ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 7 Insans, 2 Otobuss, 37.1ms\n","Speed: 3.2ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 7 Insans, 1 Otobus, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 Arabas, 5 Insans, 2 Otobuss, 36.8ms\n","Speed: 2.3ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 7 Insans, 2 Otobuss, 36.8ms\n","Speed: 2.5ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 6 Insans, 2 Otobuss, 35.5ms\n","Speed: 2.7ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 7 Insans, 2 Otobuss, 37.6ms\n","Speed: 2.8ms preprocess, 37.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 7 Insans, 1 Otobus, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 8 Insans, 1 Otobus, 34.9ms\n","Speed: 2.2ms preprocess, 34.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 7 Insans, 1 Otobus, 36.1ms\n","Speed: 2.6ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 7 Insans, 1 Otobus, 37.1ms\n","Speed: 2.5ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 6 Insans, 2 Otobuss, 35.4ms\n","Speed: 2.5ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 8 Insans, 2 Otobuss, 36.0ms\n","Speed: 2.7ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 7 Insans, 2 Otobuss, 37.3ms\n","Speed: 2.3ms preprocess, 37.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 7 Insans, 2 Otobuss, 35.4ms\n","Speed: 2.5ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 8 Insans, 2 Otobuss, 36.1ms\n","Speed: 2.4ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 6 Insans, 2 Otobuss, 37.3ms\n","Speed: 3.4ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 7 Insans, 1 Otobus, 35.0ms\n","Speed: 2.8ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 8 Insans, 2 Otobuss, 35.6ms\n","Speed: 2.6ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 4 Insans, 38.0ms\n","Speed: 2.6ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 6 Insans, 2 Otobuss, 36.1ms\n","Speed: 2.3ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 6 Insans, 1 Otobus, 35.5ms\n","Speed: 2.2ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 5 Insans, 1 Otobus, 34.5ms\n","Speed: 3.2ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 6 Insans, 1 Otobus, 35.4ms\n","Speed: 2.8ms preprocess, 35.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 8 Insans, 1 Otobus, 38.0ms\n","Speed: 2.4ms preprocess, 38.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 7 Insans, 2 Otobuss, 34.9ms\n","Speed: 2.8ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 7 Insans, 2 Otobuss, 36.1ms\n","Speed: 2.6ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 6 Insans, 1 Otobus, 36.6ms\n","Speed: 2.3ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 5 Insans, 35.4ms\n","Speed: 2.5ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 6 Insans, 36.7ms\n","Speed: 2.9ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 4 Insans, 38.5ms\n","Speed: 2.2ms preprocess, 38.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 6 Insans, 35.4ms\n","Speed: 2.2ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 6 Insans, 1 Otobus, 35.5ms\n","Speed: 2.2ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 6 Insans, 37.7ms\n","Speed: 2.3ms preprocess, 37.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 6 Insans, 1 Otobus, 36.1ms\n","Speed: 2.6ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 3 Insans, 35.5ms\n","Speed: 2.3ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 7 Insans, 1 Otobus, 37.7ms\n","Speed: 2.4ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 7 Insans, 35.7ms\n","Speed: 2.7ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 7 Insans, 35.1ms\n","Speed: 2.5ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 7 Insans, 37.4ms\n","Speed: 2.6ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 5 Insans, 36.7ms\n","Speed: 2.4ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 8 Insans, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 6 Insans, 37.0ms\n","Speed: 2.9ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 7 Insans, 1 Otobus, 34.7ms\n","Speed: 3.2ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 7 Insans, 36.2ms\n","Speed: 2.7ms preprocess, 36.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 6 Insans, 1 Otobus, 37.8ms\n","Speed: 2.4ms preprocess, 37.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 4 Insans, 36.6ms\n","Speed: 2.3ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 5 Insans, 35.6ms\n","Speed: 3.1ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 6 Insans, 38.1ms\n","Speed: 2.5ms preprocess, 38.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 6 Insans, 35.4ms\n","Speed: 2.5ms preprocess, 35.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 5 Insans, 36.3ms\n","Speed: 2.2ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 5 Insans, 1 Otobus, 33.4ms\n","Speed: 2.3ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 5 Insans, 1 Otobus, 36.3ms\n","Speed: 2.5ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 4 Insans, 37.6ms\n","Speed: 2.4ms preprocess, 37.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 6 Insans, 34.7ms\n","Speed: 2.6ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 4 Insans, 35.5ms\n","Speed: 2.5ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 4 Insans, 37.2ms\n","Speed: 3.1ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 4 Insans, 35.1ms\n","Speed: 3.4ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 2 Insans, 35.5ms\n","Speed: 2.3ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 3 Insans, 37.0ms\n","Speed: 2.5ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 3 Insans, 1 Otobus, 35.0ms\n","Speed: 2.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 5 Insans, 35.2ms\n","Speed: 2.7ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 5 Insans, 36.1ms\n","Speed: 3.1ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 3 Insans, 35.8ms\n","Speed: 2.7ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 3 Insans, 35.1ms\n","Speed: 2.1ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 2 Insans, 36.5ms\n","Speed: 2.4ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 3 Insans, 36.0ms\n","Speed: 2.5ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 5 Insans, 35.4ms\n","Speed: 3.0ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 4 Insans, 36.4ms\n","Speed: 2.7ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 6 Insans, 1 Otobus, 37.2ms\n","Speed: 2.5ms preprocess, 37.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 6 Insans, 34.9ms\n","Speed: 2.4ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 4 Insans, 36.5ms\n","Speed: 2.2ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 3 Insans, 37.5ms\n","Speed: 3.2ms preprocess, 37.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 3 Insans, 35.7ms\n","Speed: 2.3ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 4 Insans, 36.1ms\n","Speed: 2.9ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 5 Insans, 1 Otobus, 37.3ms\n","Speed: 2.3ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 4 Insans, 1 Otobus, 35.4ms\n","Speed: 2.2ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 3 Insans, 1 Otobus, 35.8ms\n","Speed: 2.6ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 5 Insans, 1 Otobus, 37.5ms\n","Speed: 2.3ms preprocess, 37.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 3 Insans, 35.8ms\n","Speed: 2.7ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Insan, 33.3ms\n","Speed: 2.9ms preprocess, 33.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 2 Insans, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 5 Insans, 1 Otobus, 36.3ms\n","Speed: 3.0ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 3 Insans, 1 Motor, 1 Otobus, 36.5ms\n","Speed: 3.2ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 3 Insans, 1 Motor, 1 Otobus, 35.2ms\n","Speed: 2.5ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 2 Insans, 1 Motor, 1 Otobus, 36.2ms\n","Speed: 2.9ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 4 Insans, 1 Otobus, 37.9ms\n","Speed: 2.4ms preprocess, 37.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 4 Insans, 35.5ms\n","Speed: 2.5ms preprocess, 35.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 1 Insan, 36.3ms\n","Speed: 2.2ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 2 Insans, 1 Motor, 1 Otobus, 36.5ms\n","Speed: 2.7ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 4 Insans, 1 Otobus, 35.0ms\n","Speed: 2.8ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 3 Insans, 1 Otobus, 35.9ms\n","Speed: 2.5ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 2 Insans, 1 Otobus, 38.0ms\n","Speed: 2.4ms preprocess, 38.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 2 Insans, 1 Motor, 1 Otobus, 35.9ms\n","Speed: 2.1ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 5 Insans, 1 Otobus, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 4 Insans, 1 Motor, 1 Otobus, 37.8ms\n","Speed: 2.2ms preprocess, 37.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 4 Insans, 1 Otobus, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 5 Insans, 1 Otobus, 35.6ms\n","Speed: 2.7ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 6 Insans, 1 Motor, 1 Otobus, 38.4ms\n","Speed: 2.5ms preprocess, 38.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 3 Insans, 1 Motor, 1 Otobus, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 4 Insans, 1 Otobus, 36.1ms\n","Speed: 2.6ms preprocess, 36.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 5 Insans, 1 Otobus, 37.4ms\n","Speed: 2.3ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 8 Insans, 35.5ms\n","Speed: 2.4ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 4 Insans, 1 Otobus, 35.6ms\n","Speed: 2.9ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 5 Insans, 36.2ms\n","Speed: 3.3ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 3 Insans, 1 Otobus, 35.2ms\n","Speed: 2.7ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 4 Insans, 1 Otobus, 36.7ms\n","Speed: 3.3ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 5 Insans, 1 Otobus, 35.5ms\n","Speed: 2.3ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 5 Insans, 35.7ms\n","Speed: 2.3ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 5 Insans, 33.2ms\n","Speed: 3.0ms preprocess, 33.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 4 Insans, 35.0ms\n","Speed: 2.6ms preprocess, 35.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 5 Insans, 36.8ms\n","Speed: 2.8ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 1 Insan, 38.0ms\n","Speed: 2.8ms preprocess, 38.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 1 Insan, 36.1ms\n","Speed: 2.5ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 36.1ms\n","Speed: 2.8ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 36.9ms\n","Speed: 2.7ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 36.0ms\n","Speed: 2.4ms preprocess, 36.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 36.3ms\n","Speed: 2.4ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 38.0ms\n","Speed: 2.3ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.1ms\n","Speed: 3.0ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.6ms\n","Speed: 2.7ms preprocess, 35.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 37.2ms\n","Speed: 2.7ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.9ms\n","Speed: 3.0ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 37.8ms\n","Speed: 2.5ms preprocess, 37.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.6ms\n","Speed: 2.2ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.3ms\n","Speed: 3.0ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 38.0ms\n","Speed: 2.1ms preprocess, 38.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.4ms\n","Speed: 2.2ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 35.2ms\n","Speed: 2.3ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 38.5ms\n","Speed: 2.6ms preprocess, 38.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.9ms\n","Speed: 2.6ms preprocess, 35.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.5ms\n","Speed: 2.6ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 36.6ms\n","Speed: 2.4ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 1 Insan, 36.1ms\n","Speed: 2.6ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 1 Insan, 35.2ms\n","Speed: 3.1ms preprocess, 35.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 36.4ms\n","Speed: 2.7ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 37.5ms\n","Speed: 2.3ms preprocess, 37.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 2 Insans, 33.7ms\n","Speed: 2.4ms preprocess, 33.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 2 Insans, 36.1ms\n","Speed: 2.4ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 2 Insans, 35.3ms\n","Speed: 3.0ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 35.7ms\n","Speed: 3.4ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 2 Insans, 35.6ms\n","Speed: 3.0ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 34.8ms\n","Speed: 2.3ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 2 Insans, 37.4ms\n","Speed: 3.1ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 2 Insans, 35.1ms\n","Speed: 2.5ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 3 Insans, 36.0ms\n","Speed: 3.0ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 2 Insans, 36.8ms\n","Speed: 3.3ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 2 Insans, 35.1ms\n","Speed: 2.3ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 3 Insans, 36.1ms\n","Speed: 3.3ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 1 Insan, 38.0ms\n","Speed: 2.7ms preprocess, 38.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 2 Insans, 34.7ms\n","Speed: 3.1ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 1 Insan, 35.0ms\n","Speed: 3.6ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 2 Insans, 36.9ms\n","Speed: 2.5ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 1 Insan, 34.2ms\n","Speed: 3.5ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 37.0ms\n","Speed: 3.2ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 35.7ms\n","Speed: 3.4ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 1 Insan, 36.8ms\n","Speed: 2.5ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 36.3ms\n","Speed: 3.2ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 36.1ms\n","Speed: 2.4ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 35.5ms\n","Speed: 3.2ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 36.7ms\n","Speed: 2.4ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 2 Insans, 35.8ms\n","Speed: 3.0ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 2 Insans, 34.6ms\n","Speed: 3.4ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 2 Insans, 33.4ms\n","Speed: 2.2ms preprocess, 33.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 2 Insans, 35.0ms\n","Speed: 2.6ms preprocess, 35.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 1 Insan, 36.8ms\n","Speed: 2.3ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 1 Insan, 36.1ms\n","Speed: 2.3ms preprocess, 36.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 34.8ms\n","Speed: 2.1ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 36.7ms\n","Speed: 2.9ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 35.7ms\n","Speed: 2.7ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 35.6ms\n","Speed: 3.3ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 37.1ms\n","Speed: 2.4ms preprocess, 37.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 1 Insan, 34.8ms\n","Speed: 3.0ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 35.3ms\n","Speed: 2.7ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 1 Insan, 37.2ms\n","Speed: 3.2ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 1 Insan, 34.5ms\n","Speed: 3.2ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 35.4ms\n","Speed: 2.7ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 36.1ms\n","Speed: 3.4ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 35.4ms\n","Speed: 2.8ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.8ms\n","Speed: 3.3ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 35.8ms\n","Speed: 2.6ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 35.1ms\n","Speed: 2.8ms preprocess, 35.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 36.7ms\n","Speed: 3.7ms preprocess, 36.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.8ms\n","Speed: 3.6ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 2 Insans, 35.3ms\n","Speed: 2.1ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 34.7ms\n","Speed: 2.3ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 1 Insan, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 37.1ms\n","Speed: 2.5ms preprocess, 37.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 1 Insan, 35.6ms\n","Speed: 2.2ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 35.9ms\n","Speed: 2.7ms preprocess, 35.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 2 Insans, 36.8ms\n","Speed: 3.2ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 1 Insan, 32.9ms\n","Speed: 2.4ms preprocess, 32.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.2ms\n","Speed: 3.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 2 Insans, 35.0ms\n","Speed: 2.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 36.0ms\n","Speed: 2.9ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 36.6ms\n","Speed: 3.2ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.6ms\n","Speed: 3.0ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 36.4ms\n","Speed: 2.7ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.8ms\n","Speed: 2.4ms preprocess, 35.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 36.0ms\n","Speed: 2.9ms preprocess, 36.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.9ms\n","Speed: 2.5ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.2ms\n","Speed: 2.1ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 2 Insans, 36.1ms\n","Speed: 2.9ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 36.7ms\n","Speed: 2.3ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 34.9ms\n","Speed: 2.3ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.9ms\n","Speed: 2.5ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 37.1ms\n","Speed: 2.5ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.4ms\n","Speed: 2.3ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 34.6ms\n","Speed: 2.9ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 36.8ms\n","Speed: 3.3ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 35.8ms\n","Speed: 2.8ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 34.8ms\n","Speed: 2.7ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 35.6ms\n","Speed: 3.5ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 36.5ms\n","Speed: 2.6ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 35.2ms\n","Speed: 2.7ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 3 Insans, 36.0ms\n","Speed: 3.4ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 35.6ms\n","Speed: 2.9ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 35.1ms\n","Speed: 2.5ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 33.2ms\n","Speed: 2.5ms preprocess, 33.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 2 Insans, 35.3ms\n","Speed: 2.4ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 36.1ms\n","Speed: 3.2ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 36.5ms\n","Speed: 3.1ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 35.5ms\n","Speed: 3.2ms preprocess, 35.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 36.4ms\n","Speed: 2.5ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 38.1ms\n","Speed: 2.3ms preprocess, 38.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 37.2ms\n","Speed: 2.3ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.0ms\n","Speed: 2.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.6ms\n","Speed: 2.4ms preprocess, 35.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 37.3ms\n","Speed: 2.3ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.7ms\n","Speed: 2.6ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 35.2ms\n","Speed: 2.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 36.8ms\n","Speed: 2.7ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 36.9ms\n","Speed: 3.3ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 2 Insans, 35.1ms\n","Speed: 2.4ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 36.4ms\n","Speed: 2.7ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 34.5ms\n","Speed: 2.4ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.6ms\n","Speed: 2.3ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 38.1ms\n","Speed: 2.8ms preprocess, 38.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 34.8ms\n","Speed: 2.5ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 35.3ms\n","Speed: 2.3ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 36.3ms\n","Speed: 2.9ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 35.1ms\n","Speed: 2.5ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.2ms\n","Speed: 3.1ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 36.8ms\n","Speed: 2.6ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 1 Insan, 34.3ms\n","Speed: 2.6ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 36.0ms\n","Speed: 2.1ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 35.1ms\n","Speed: 3.4ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.4ms\n","Speed: 2.4ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 36.5ms\n","Speed: 2.4ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 37.3ms\n","Speed: 2.7ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 35.2ms\n","Speed: 3.3ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 37.3ms\n","Speed: 2.2ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 36.7ms\n","Speed: 2.5ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 2 Insans, 34.7ms\n","Speed: 2.8ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 2 Insans, 35.9ms\n","Speed: 2.3ms preprocess, 35.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 36.4ms\n","Speed: 3.0ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.1ms\n","Speed: 2.7ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 35.8ms\n","Speed: 3.4ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.8ms\n","Speed: 3.3ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 34.8ms\n","Speed: 2.8ms preprocess, 34.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 35.4ms\n","Speed: 2.8ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 2 Insans, 36.2ms\n","Speed: 3.2ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.3ms\n","Speed: 2.5ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 2 Insans, 35.7ms\n","Speed: 3.1ms preprocess, 35.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 2 Insans, 36.5ms\n","Speed: 3.4ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.1ms\n","Speed: 2.4ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 2 Insans, 36.0ms\n","Speed: 2.7ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 36.0ms\n","Speed: 2.6ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 34.5ms\n","Speed: 2.3ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 35.3ms\n","Speed: 2.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 38.0ms\n","Speed: 2.6ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 34.6ms\n","Speed: 2.3ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.6ms\n","Speed: 2.4ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 33.0ms\n","Speed: 2.3ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 2 Insans, 36.7ms\n","Speed: 2.2ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 36.3ms\n","Speed: 2.3ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 37.4ms\n","Speed: 3.2ms preprocess, 37.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 34.8ms\n","Speed: 2.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 37.5ms\n","Speed: 2.5ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 37.3ms\n","Speed: 3.0ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 34.9ms\n","Speed: 2.5ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 37.6ms\n","Speed: 2.3ms preprocess, 37.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 34.7ms\n","Speed: 3.2ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 35.6ms\n","Speed: 3.1ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 38.1ms\n","Speed: 2.5ms preprocess, 38.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 34.9ms\n","Speed: 2.6ms preprocess, 34.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 1 Insan, 35.5ms\n","Speed: 3.2ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 1 Insan, 36.4ms\n","Speed: 2.3ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 35.9ms\n","Speed: 2.3ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 35.5ms\n","Speed: 3.1ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 37.9ms\n","Speed: 2.6ms preprocess, 37.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 34.7ms\n","Speed: 2.8ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 34.4ms\n","Speed: 3.1ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 36.6ms\n","Speed: 2.0ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 34.9ms\n","Speed: 2.6ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 3 Insans, 31.3ms\n","Speed: 2.2ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 35.4ms\n","Speed: 2.9ms preprocess, 35.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 36.3ms\n","Speed: 2.8ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 37.2ms\n","Speed: 2.2ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 34.5ms\n","Speed: 2.5ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 2 Insans, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 2 Insans, 36.1ms\n","Speed: 3.2ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 37.1ms\n","Speed: 2.5ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 35.2ms\n","Speed: 2.4ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 36.0ms\n","Speed: 2.6ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 36.3ms\n","Speed: 2.3ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 34.7ms\n","Speed: 2.5ms preprocess, 34.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 36.6ms\n","Speed: 2.4ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 37.9ms\n","Speed: 2.7ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 34.4ms\n","Speed: 3.5ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 34.5ms\n","Speed: 2.5ms preprocess, 34.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 37.2ms\n","Speed: 2.3ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 35.9ms\n","Speed: 2.3ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 35.1ms\n","Speed: 2.3ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 37.0ms\n","Speed: 3.2ms preprocess, 37.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 34.8ms\n","Speed: 2.7ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 36.0ms\n","Speed: 3.4ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 34.9ms\n","Speed: 2.9ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 34.5ms\n","Speed: 3.1ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 36.4ms\n","Speed: 2.2ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 34.4ms\n","Speed: 2.8ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 35.6ms\n","Speed: 2.7ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 1 Insan, 33.2ms\n","Speed: 2.9ms preprocess, 33.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 35.0ms\n","Speed: 3.4ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 1 Insan, 37.0ms\n","Speed: 2.9ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 35.2ms\n","Speed: 2.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 35.1ms\n","Speed: 2.9ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 1 Insan, 36.3ms\n","Speed: 2.8ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 35.7ms\n","Speed: 2.2ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.1ms\n","Speed: 2.7ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.4ms\n","Speed: 2.8ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.5ms\n","Speed: 2.9ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.8ms\n","Speed: 2.5ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.9ms\n","Speed: 2.4ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.9ms\n","Speed: 2.4ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 1 Insan, 35.4ms\n","Speed: 2.4ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.9ms\n","Speed: 3.0ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 1 Insan, 37.2ms\n","Speed: 3.2ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 2 Insans, 35.1ms\n","Speed: 2.8ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 1 Insan, 35.0ms\n","Speed: 2.3ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 36.1ms\n","Speed: 2.4ms preprocess, 36.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 37.0ms\n","Speed: 2.1ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 35.0ms\n","Speed: 2.9ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 36.1ms\n","Speed: 2.3ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 36.7ms\n","Speed: 2.6ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 34.3ms\n","Speed: 2.2ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 35.6ms\n","Speed: 2.3ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 36.3ms\n","Speed: 2.5ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 3 Insans, 35.8ms\n","Speed: 2.6ms preprocess, 35.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 35.1ms\n","Speed: 2.1ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 1 Insan, 35.3ms\n","Speed: 2.3ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 2 Insans, 33.2ms\n","Speed: 2.5ms preprocess, 33.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.6ms\n","Speed: 2.7ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 36.5ms\n","Speed: 3.0ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 35.3ms\n","Speed: 2.4ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 37.0ms\n","Speed: 2.9ms preprocess, 37.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 34.5ms\n","Speed: 5.7ms preprocess, 34.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 36.3ms\n","Speed: 3.4ms preprocess, 36.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 34.3ms\n","Speed: 3.2ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 35.0ms\n","Speed: 2.8ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 35.6ms\n","Speed: 3.1ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 34.7ms\n","Speed: 2.4ms preprocess, 34.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 34.6ms\n","Speed: 2.5ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 36.7ms\n","Speed: 2.9ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 36.7ms\n","Speed: 2.7ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 36.0ms\n","Speed: 2.1ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 36.6ms\n","Speed: 2.2ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 2 Insans, 34.9ms\n","Speed: 3.3ms preprocess, 34.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 35.3ms\n","Speed: 2.4ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 36.3ms\n","Speed: 2.7ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 2 Insans, 35.2ms\n","Speed: 3.6ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 1 Insan, 36.1ms\n","Speed: 2.4ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 1 Insan, 35.7ms\n","Speed: 2.7ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 34.6ms\n","Speed: 2.5ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 2 Insans, 35.1ms\n","Speed: 2.5ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 2 Insans, 36.4ms\n","Speed: 2.8ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 1 Insan, 34.4ms\n","Speed: 2.6ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 34.7ms\n","Speed: 2.8ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 2 Insans, 33.3ms\n","Speed: 2.6ms preprocess, 33.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 2 Insans, 34.8ms\n","Speed: 3.1ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 36.2ms\n","Speed: 2.5ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 2 Insans, 35.1ms\n","Speed: 3.3ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 2 Insans, 35.8ms\n","Speed: 2.4ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 3 Insans, 35.0ms\n","Speed: 3.1ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 1 Insan, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 4 Insans, 37.3ms\n","Speed: 2.4ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 1 Insan, 34.4ms\n","Speed: 3.0ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 4 Insans, 34.6ms\n","Speed: 2.4ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 3 Insans, 36.9ms\n","Speed: 2.6ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 2 Insans, 32.7ms\n","Speed: 3.5ms preprocess, 32.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 2 Insans, 34.9ms\n","Speed: 2.2ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 2 Insans, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 4 Insans, 35.6ms\n","Speed: 2.9ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 4 Insans, 34.5ms\n","Speed: 3.7ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 4 Insans, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 3 Insans, 35.1ms\n","Speed: 2.6ms preprocess, 35.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 3 Insans, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 1 Insan, 35.3ms\n","Speed: 3.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 2 Insans, 35.2ms\n","Speed: 3.1ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 2 Insans, 34.5ms\n","Speed: 2.8ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 2 Insans, 36.5ms\n","Speed: 3.3ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 3 Insans, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 2 Insans, 35.2ms\n","Speed: 2.2ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 4 Insans, 36.2ms\n","Speed: 3.6ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 3 Insans, 34.7ms\n","Speed: 2.3ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 3 Insans, 35.2ms\n","Speed: 2.4ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 2 Insans, 32.2ms\n","Speed: 3.1ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 2 Insans, 34.9ms\n","Speed: 3.3ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 4 Insans, 36.6ms\n","Speed: 2.4ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 2 Insans, 34.1ms\n","Speed: 3.2ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 Arabas, 1 Insan, 34.6ms\n","Speed: 3.5ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 2 Insans, 36.1ms\n","Speed: 2.6ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 34.3ms\n","Speed: 3.3ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 34.8ms\n","Speed: 2.8ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 1 Insan, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 1 Insan, 34.9ms\n","Speed: 3.0ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 2 Insans, 35.4ms\n","Speed: 2.8ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 3 Insans, 35.4ms\n","Speed: 3.4ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 2 Insans, 34.2ms\n","Speed: 3.4ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 2 Insans, 36.0ms\n","Speed: 2.4ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 2 Insans, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 2 Insans, 34.5ms\n","Speed: 3.0ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 2 Insans, 36.3ms\n","Speed: 3.4ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 1 Insan, 34.2ms\n","Speed: 3.1ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 2 Insans, 33.9ms\n","Speed: 3.1ms preprocess, 33.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 1 Insan, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 1 Insan, 35.5ms\n","Speed: 3.7ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 1 Insan, 34.5ms\n","Speed: 2.3ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 2 Insans, 34.8ms\n","Speed: 3.2ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 2 Insans, 36.3ms\n","Speed: 2.3ms preprocess, 36.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.4ms\n","Speed: 3.3ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 2 Insans, 33.9ms\n","Speed: 2.3ms preprocess, 33.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 36.8ms\n","Speed: 2.3ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 35.7ms\n","Speed: 2.8ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.3ms\n","Speed: 2.6ms preprocess, 34.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 32.5ms\n","Speed: 2.9ms preprocess, 32.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.2ms\n","Speed: 3.5ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.4ms\n","Speed: 2.5ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 36.6ms\n","Speed: 2.7ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 1 Insan, 35.0ms\n","Speed: 2.3ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 1 Insan, 34.8ms\n","Speed: 3.3ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 1 Insan, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 2 Insans, 34.1ms\n","Speed: 2.5ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 2 Insans, 35.3ms\n","Speed: 2.7ms preprocess, 35.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 1 Insan, 35.0ms\n","Speed: 2.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 36.6ms\n","Speed: 2.6ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 34.3ms\n","Speed: 2.6ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 35.0ms\n","Speed: 2.3ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 36.1ms\n","Speed: 3.4ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 33.9ms\n","Speed: 3.4ms preprocess, 33.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 35.0ms\n","Speed: 2.6ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 37.9ms\n","Speed: 2.9ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.3ms\n","Speed: 2.5ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 1 Insan, 34.4ms\n","Speed: 3.3ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.6ms\n","Speed: 2.4ms preprocess, 35.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.1ms\n","Speed: 2.3ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.7ms\n","Speed: 2.9ms preprocess, 35.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 37.1ms\n","Speed: 2.3ms preprocess, 37.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.5ms\n","Speed: 3.3ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.1ms\n","Speed: 2.8ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 37.4ms\n","Speed: 2.6ms preprocess, 37.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.0ms\n","Speed: 2.6ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 34.7ms\n","Speed: 2.6ms preprocess, 34.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 32.5ms\n","Speed: 3.2ms preprocess, 32.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 34.4ms\n","Speed: 2.3ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 35.8ms\n","Speed: 2.6ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 34.1ms\n","Speed: 3.4ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 34.8ms\n","Speed: 2.7ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 37.2ms\n","Speed: 2.9ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.9ms\n","Speed: 2.5ms preprocess, 34.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 35.2ms\n","Speed: 2.2ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 36.0ms\n","Speed: 2.7ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.5ms\n","Speed: 2.1ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 34.8ms\n","Speed: 2.7ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 36.1ms\n","Speed: 2.5ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.5ms\n","Speed: 2.4ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.7ms\n","Speed: 3.5ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 36.3ms\n","Speed: 2.4ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.3ms\n","Speed: 3.2ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 34.0ms\n","Speed: 3.4ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 35.0ms\n","Speed: 2.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 36.6ms\n","Speed: 3.4ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 34.3ms\n","Speed: 2.3ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.4ms\n","Speed: 2.1ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 36.0ms\n","Speed: 3.1ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.0ms\n","Speed: 3.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.3ms\n","Speed: 2.3ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.8ms\n","Speed: 3.3ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.5ms\n","Speed: 3.4ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.3ms\n","Speed: 2.7ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 32.4ms\n","Speed: 2.7ms preprocess, 32.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.4ms\n","Speed: 2.2ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.4ms\n","Speed: 2.2ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.0ms\n","Speed: 3.3ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.7ms\n","Speed: 3.5ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.1ms\n","Speed: 2.7ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.2ms\n","Speed: 2.3ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.9ms\n","Speed: 3.4ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.2ms\n","Speed: 3.1ms preprocess, 34.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.3ms\n","Speed: 3.1ms preprocess, 34.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.0ms\n","Speed: 2.9ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.5ms\n","Speed: 2.8ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.6ms\n","Speed: 2.7ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 36.4ms\n","Speed: 2.7ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.9ms\n","Speed: 3.4ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.6ms\n","Speed: 2.4ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 36.3ms\n","Speed: 2.8ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 33.6ms\n","Speed: 3.3ms preprocess, 33.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.6ms\n","Speed: 3.4ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.6ms\n","Speed: 2.6ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 36.7ms\n","Speed: 2.2ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.7ms\n","Speed: 3.2ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.3ms\n","Speed: 2.7ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.5ms\n","Speed: 2.4ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.4ms\n","Speed: 2.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 32.3ms\n","Speed: 2.8ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.6ms\n","Speed: 2.7ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 36.1ms\n","Speed: 2.1ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 36.3ms\n","Speed: 3.4ms preprocess, 36.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.6ms\n","Speed: 3.4ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.7ms\n","Speed: 3.0ms preprocess, 34.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 32.6ms\n","Speed: 3.4ms preprocess, 32.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 1 Insan, 34.2ms\n","Speed: 3.1ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 36.2ms\n","Speed: 2.8ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.9ms\n","Speed: 2.4ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.0ms\n","Speed: 3.4ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.5ms\n","Speed: 3.4ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 33.9ms\n","Speed: 2.5ms preprocess, 33.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 37.0ms\n","Speed: 2.8ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.0ms\n","Speed: 2.1ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.9ms\n","Speed: 3.5ms preprocess, 34.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 36.2ms\n","Speed: 3.1ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 1 Kamyon, 34.3ms\n","Speed: 3.2ms preprocess, 34.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.4ms\n","Speed: 3.5ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.1ms\n","Speed: 3.7ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Kamyon, 34.2ms\n","Speed: 3.5ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.6ms\n","Speed: 2.4ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.4ms\n","Speed: 2.5ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 1 Kamyon, 34.6ms\n","Speed: 3.5ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 34.7ms\n","Speed: 2.5ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 37.2ms\n","Speed: 3.3ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 33.0ms\n","Speed: 2.9ms preprocess, 33.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 34.9ms\n","Speed: 2.5ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 35.0ms\n","Speed: 3.6ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 1 Insan, 36.7ms\n","Speed: 2.8ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Insan, 34.1ms\n","Speed: 2.9ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 35.3ms\n","Speed: 2.5ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 36.7ms\n","Speed: 3.3ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 1 Insan, 35.1ms\n","Speed: 2.2ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.8ms\n","Speed: 2.6ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.0ms\n","Speed: 2.2ms preprocess, 36.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 35.4ms\n","Speed: 2.6ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.4ms\n","Speed: 2.8ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 1 Kamyon, 34.7ms\n","Speed: 2.3ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Motor, 36.5ms\n","Speed: 3.5ms preprocess, 36.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Motor, 33.4ms\n","Speed: 2.9ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 1 Motor, 34.0ms\n","Speed: 3.1ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.1ms\n","Speed: 2.5ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 33.9ms\n","Speed: 2.7ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 33.4ms\n","Speed: 2.5ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 34.0ms\n","Speed: 3.6ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 Arabas, 36.2ms\n","Speed: 2.4ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 Arabas, 34.5ms\n","Speed: 2.5ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 35.7ms\n","Speed: 3.3ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 36.1ms\n","Speed: 2.4ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 34.1ms\n","Speed: 2.7ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 34.3ms\n","Speed: 2.4ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 36.6ms\n","Speed: 2.9ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 33.8ms\n","Speed: 2.8ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 32.6ms\n","Speed: 2.6ms preprocess, 32.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 1 Kamyon, 35.4ms\n","Speed: 2.7ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 34.6ms\n","Speed: 3.1ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.8ms\n","Speed: 2.7ms preprocess, 35.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 34.6ms\n","Speed: 2.7ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.5ms\n","Speed: 3.1ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.6ms\n","Speed: 3.3ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 1 Kamyon, 33.5ms\n","Speed: 2.6ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.6ms\n","Speed: 2.7ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 1 Kamyon, 36.2ms\n","Speed: 3.0ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 1 Kamyon, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 35.9ms\n","Speed: 2.2ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 1 Insan, 1 Kamyon, 1 Motor, 35.7ms\n","Speed: 2.9ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 1 Insan, 34.3ms\n","Speed: 3.2ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 1 Kamyon, 36.4ms\n","Speed: 3.3ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Insan, 1 Kamyon, 33.3ms\n","Speed: 3.4ms preprocess, 33.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 1 Insan, 1 Kamyon, 34.6ms\n","Speed: 3.1ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 1 Insan, 1 Kamyon, 35.6ms\n","Speed: 2.8ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 1 Kamyon, 35.0ms\n","Speed: 2.7ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 1 Kamyon, 34.3ms\n","Speed: 3.3ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.3ms\n","Speed: 3.5ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.5ms\n","Speed: 2.4ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 34.7ms\n","Speed: 3.3ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 Arabas, 34.9ms\n","Speed: 2.8ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 34.9ms\n","Speed: 3.7ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 34.3ms\n","Speed: 3.1ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.6ms\n","Speed: 3.2ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 31.6ms\n","Speed: 2.8ms preprocess, 31.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 34.7ms\n","Speed: 3.0ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 37.0ms\n","Speed: 3.4ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.6ms\n","Speed: 2.6ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.3ms\n","Speed: 3.0ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.4ms\n","Speed: 3.5ms preprocess, 36.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.4ms\n","Speed: 2.6ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.2ms\n","Speed: 3.2ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.6ms\n","Speed: 2.2ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 35.6ms\n","Speed: 2.7ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.0ms\n","Speed: 2.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.3ms\n","Speed: 2.5ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.3ms\n","Speed: 2.1ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.0ms\n","Speed: 2.3ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.5ms\n","Speed: 3.2ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 36.0ms\n","Speed: 2.2ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 36.6ms\n","Speed: 2.4ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Insan, 34.2ms\n","Speed: 2.4ms preprocess, 34.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 1 Insan, 34.6ms\n","Speed: 2.3ms preprocess, 34.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.5ms\n","Speed: 3.5ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 33.7ms\n","Speed: 2.8ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 1 Insan, 34.3ms\n","Speed: 2.7ms preprocess, 34.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 1 Insan, 35.1ms\n","Speed: 3.1ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.3ms\n","Speed: 2.4ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 1 Insan, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Insan, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 2 Insans, 37.1ms\n","Speed: 2.5ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 2 Insans, 34.7ms\n","Speed: 3.5ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 1 Insan, 31.5ms\n","Speed: 3.5ms preprocess, 31.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 1 Insan, 34.9ms\n","Speed: 3.5ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 1 Insan, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Insan, 34.0ms\n","Speed: 3.2ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Insan, 34.2ms\n","Speed: 2.8ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 1 Insan, 35.3ms\n","Speed: 2.5ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.2ms\n","Speed: 2.5ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.5ms\n","Speed: 2.6ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.5ms\n","Speed: 3.6ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.7ms\n","Speed: 2.4ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 1 Insan, 36.7ms\n","Speed: 2.9ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 1 Insan, 33.4ms\n","Speed: 3.6ms preprocess, 33.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.7ms\n","Speed: 2.7ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.0ms\n","Speed: 2.5ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 1 Insan, 35.5ms\n","Speed: 3.4ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Insan, 36.3ms\n","Speed: 2.7ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 1 Insan, 34.0ms\n","Speed: 3.3ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 Arabas, 35.0ms\n","Speed: 2.8ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 Arabas, 1 Insan, 36.6ms\n","Speed: 3.5ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 2 Insans, 34.5ms\n","Speed: 3.4ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 Arabas, 2 Insans, 35.0ms\n","Speed: 3.3ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 Arabas, 2 Insans, 36.5ms\n","Speed: 2.6ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 Arabas, 1 Insan, 34.3ms\n","Speed: 2.7ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 Arabas, 2 Insans, 35.1ms\n","Speed: 2.9ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 Arabas, 2 Insans, 35.8ms\n","Speed: 2.8ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 Arabas, 1 Insan, 37.1ms\n","Speed: 3.4ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 Arabas, 1 Insan, 37.1ms\n","Speed: 2.7ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 Arabas, 1 Insan, 33.2ms\n","Speed: 3.0ms preprocess, 33.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 35.9ms\n","Speed: 2.8ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 1 Insan, 35.2ms\n","Speed: 2.5ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 1 Insan, 34.4ms\n","Speed: 3.4ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 1 Insan, 33.8ms\n","Speed: 3.2ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 1 Insan, 34.4ms\n","Speed: 3.2ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 2 Insans, 35.4ms\n","Speed: 3.2ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 31 Arabas, 1 Insan, 35.2ms\n","Speed: 3.2ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 1 Insan, 34.2ms\n","Speed: 2.7ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 1 Insan, 34.7ms\n","Speed: 3.2ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 1 Insan, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 1 Insan, 34.4ms\n","Speed: 2.9ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 1 Insan, 34.7ms\n","Speed: 3.0ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 1 Insan, 35.1ms\n","Speed: 2.5ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 1 Insan, 37.2ms\n","Speed: 2.9ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 1 Insan, 37.1ms\n","Speed: 3.4ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 1 Insan, 34.9ms\n","Speed: 3.4ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 1 Insan, 34.4ms\n","Speed: 2.5ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 1 Insan, 35.0ms\n","Speed: 3.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 1 Insan, 35.8ms\n","Speed: 2.6ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 1 Insan, 34.4ms\n","Speed: 2.4ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 33 Arabas, 1 Insan, 34.9ms\n","Speed: 2.3ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 Arabas, 1 Insan, 35.0ms\n","Speed: 3.4ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 1 Insan, 35.3ms\n","Speed: 2.7ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 1 Insan, 34.4ms\n","Speed: 2.5ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 35.0ms\n","Speed: 2.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 32 Arabas, 35.9ms\n","Speed: 3.2ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 32.3ms\n","Speed: 3.1ms preprocess, 32.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 36.1ms\n","Speed: 2.6ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 34.8ms\n","Speed: 2.4ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 34.5ms\n","Speed: 2.6ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 36.0ms\n","Speed: 2.6ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 36.0ms\n","Speed: 2.5ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 34.5ms\n","Speed: 3.2ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 36 Arabas, 36.4ms\n","Speed: 3.1ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 34.0ms\n","Speed: 4.3ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 35.0ms\n","Speed: 2.3ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 34 Arabas, 35.8ms\n","Speed: 3.2ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 35 Arabas, 34.1ms\n","Speed: 3.1ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 34.6ms\n","Speed: 2.7ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 34.9ms\n","Speed: 3.0ms preprocess, 34.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 35.4ms\n","Speed: 2.7ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 34.3ms\n","Speed: 3.2ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 35.7ms\n","Speed: 2.7ms preprocess, 35.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 34.9ms\n","Speed: 3.9ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 34.2ms\n","Speed: 3.2ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 43 Arabas, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 34.5ms\n","Speed: 2.7ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 34.9ms\n","Speed: 3.1ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 35.6ms\n","Speed: 2.3ms preprocess, 35.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 43 Arabas, 34.3ms\n","Speed: 2.3ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 43 Arabas, 35.1ms\n","Speed: 3.0ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 43 Arabas, 36.6ms\n","Speed: 2.4ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 45 Arabas, 32.0ms\n","Speed: 3.4ms preprocess, 32.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 35.4ms\n","Speed: 3.2ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 45 Arabas, 34.6ms\n","Speed: 2.6ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 45 Arabas, 34.6ms\n","Speed: 2.7ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 44 Arabas, 36.0ms\n","Speed: 2.5ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 44 Arabas, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 43 Arabas, 34.2ms\n","Speed: 2.5ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 44 Arabas, 35.0ms\n","Speed: 2.3ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 43 Arabas, 36.2ms\n","Speed: 2.2ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 43 Arabas, 34.4ms\n","Speed: 2.4ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 34.3ms\n","Speed: 2.8ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 35.4ms\n","Speed: 2.8ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 44 Arabas, 35.4ms\n","Speed: 2.8ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 43 Arabas, 34.2ms\n","Speed: 3.2ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 34.2ms\n","Speed: 3.7ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 35.7ms\n","Speed: 3.4ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 34.5ms\n","Speed: 2.6ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 34.7ms\n","Speed: 2.6ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 45 Arabas, 36.3ms\n","Speed: 2.3ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 44 Arabas, 34.3ms\n","Speed: 3.4ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 45 Arabas, 34.7ms\n","Speed: 3.3ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 44 Arabas, 36.0ms\n","Speed: 3.6ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 44 Arabas, 34.3ms\n","Speed: 2.7ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 43 Arabas, 34.2ms\n","Speed: 2.4ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 35.3ms\n","Speed: 2.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 35.5ms\n","Speed: 2.9ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 34.3ms\n","Speed: 3.2ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 43 Arabas, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 36.3ms\n","Speed: 3.2ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 32.6ms\n","Speed: 2.3ms preprocess, 32.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 39 Arabas, 36.7ms\n","Speed: 2.6ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 33.3ms\n","Speed: 3.0ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 34.4ms\n","Speed: 2.3ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 1 Insan, 35.6ms\n","Speed: 2.4ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 42 Arabas, 1 Insan, 33.3ms\n","Speed: 3.4ms preprocess, 33.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 1 Insan, 34.1ms\n","Speed: 2.6ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 41 Arabas, 1 Insan, 34.7ms\n","Speed: 2.8ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 40 Arabas, 36.3ms\n","Speed: 2.3ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 38 Arabas, 33.8ms\n","Speed: 2.8ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 37 Arabas, 34.7ms\n","Speed: 3.4ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.3ms\n","Speed: 2.3ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 34.4ms\n","Speed: 2.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.3ms\n","Speed: 3.0ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.1ms\n","Speed: 2.4ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 35.4ms\n","Speed: 2.4ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 33.7ms\n","Speed: 2.8ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 33.9ms\n","Speed: 2.3ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.0ms\n","Speed: 3.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.5ms\n","Speed: 3.2ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 34.5ms\n","Speed: 2.5ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.9ms\n","Speed: 2.5ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 33.6ms\n","Speed: 3.3ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 1 Insan, 33.8ms\n","Speed: 2.8ms preprocess, 33.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.8ms\n","Speed: 3.1ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 33.7ms\n","Speed: 2.7ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.6ms\n","Speed: 2.6ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 32.7ms\n","Speed: 2.6ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 36.4ms\n","Speed: 2.7ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.0ms\n","Speed: 2.4ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.7ms\n","Speed: 2.4ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.3ms\n","Speed: 2.8ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.4ms\n","Speed: 2.5ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.6ms\n","Speed: 2.7ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 35.8ms\n","Speed: 2.7ms preprocess, 35.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.4ms\n","Speed: 3.4ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.1ms\n","Speed: 3.4ms preprocess, 35.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.1ms\n","Speed: 3.5ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.3ms\n","Speed: 3.7ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.4ms\n","Speed: 2.5ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.1ms\n","Speed: 2.7ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.2ms\n","Speed: 2.5ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.0ms\n","Speed: 2.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.4ms\n","Speed: 2.6ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.2ms\n","Speed: 2.7ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.4ms\n","Speed: 2.3ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.6ms\n","Speed: 2.7ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.6ms\n","Speed: 3.1ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.7ms\n","Speed: 2.3ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.9ms\n","Speed: 2.8ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.6ms\n","Speed: 3.4ms preprocess, 34.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.6ms\n","Speed: 3.2ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.7ms\n","Speed: 2.6ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.5ms\n","Speed: 2.6ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 32.0ms\n","Speed: 3.5ms preprocess, 32.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.0ms\n","Speed: 3.0ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.9ms\n","Speed: 2.4ms preprocess, 35.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.2ms\n","Speed: 2.4ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.0ms\n","Speed: 2.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 34.7ms\n","Speed: 3.4ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 35.4ms\n","Speed: 2.4ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.0ms\n","Speed: 2.2ms preprocess, 36.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.5ms\n","Speed: 3.3ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.8ms\n","Speed: 2.6ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.0ms\n","Speed: 2.4ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.7ms\n","Speed: 3.3ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 36.0ms\n","Speed: 2.3ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.4ms\n","Speed: 2.7ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.5ms\n","Speed: 2.3ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.1ms\n","Speed: 2.7ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.3ms\n","Speed: 2.7ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.7ms\n","Speed: 2.3ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.4ms\n","Speed: 2.4ms preprocess, 36.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.9ms\n","Speed: 2.2ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.1ms\n","Speed: 2.3ms preprocess, 34.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.7ms\n","Speed: 2.1ms preprocess, 34.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 37.2ms\n","Speed: 2.5ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 31.6ms\n","Speed: 3.4ms preprocess, 31.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.4ms\n","Speed: 2.3ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.3ms\n","Speed: 3.5ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.2ms\n","Speed: 3.4ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.0ms\n","Speed: 2.3ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.5ms\n","Speed: 2.5ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.5ms\n","Speed: 2.6ms preprocess, 34.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.3ms\n","Speed: 3.2ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.6ms\n","Speed: 2.6ms preprocess, 35.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 34.3ms\n","Speed: 2.9ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.4ms\n","Speed: 3.1ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.3ms\n","Speed: 2.8ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.5ms\n","Speed: 2.6ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.7ms\n","Speed: 3.2ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.4ms\n","Speed: 2.7ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.2ms\n","Speed: 2.4ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.4ms\n","Speed: 2.4ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 34.8ms\n","Speed: 2.8ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 Arabas, 35.4ms\n","Speed: 3.2ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 33.7ms\n","Speed: 2.5ms preprocess, 33.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.0ms\n","Speed: 2.6ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 35.4ms\n","Speed: 2.1ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.7ms\n","Speed: 3.4ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 34.3ms\n","Speed: 3.4ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.6ms\n","Speed: 3.3ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.9ms\n","Speed: 2.4ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.4ms\n","Speed: 2.5ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 34.8ms\n","Speed: 2.7ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.3ms\n","Speed: 2.6ms preprocess, 36.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 33.0ms\n","Speed: 2.8ms preprocess, 33.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 36.1ms\n","Speed: 2.7ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.0ms\n","Speed: 3.3ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 33.3ms\n","Speed: 2.5ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.1ms\n","Speed: 2.4ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 36.4ms\n","Speed: 3.0ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 Arabas, 33.7ms\n","Speed: 2.2ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 34.4ms\n","Speed: 2.6ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 36.0ms\n","Speed: 2.1ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 35.7ms\n","Speed: 2.9ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 Arabas, 34.3ms\n","Speed: 2.9ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 Arabas, 35.0ms\n","Speed: 2.6ms preprocess, 35.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 Arabas, 37.0ms\n","Speed: 2.7ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 33.8ms\n","Speed: 2.6ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 33.6ms\n","Speed: 2.4ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 34.0ms\n","Speed: 3.3ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 Arabas, 35.8ms\n","Speed: 2.4ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 34.5ms\n","Speed: 2.6ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 34.6ms\n","Speed: 2.7ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 34.9ms\n","Speed: 3.5ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 34.4ms\n","Speed: 2.2ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 33.7ms\n","Speed: 2.6ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 34.8ms\n","Speed: 2.4ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 Arabas, 37.1ms\n","Speed: 3.2ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 34.5ms\n","Speed: 2.3ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 Arabas, 34.6ms\n","Speed: 3.2ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 Arabas, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.7ms\n","Speed: 2.8ms preprocess, 35.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.4ms\n","Speed: 2.6ms preprocess, 34.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 31.2ms\n","Speed: 3.3ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 34.3ms\n","Speed: 3.3ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 35.6ms\n","Speed: 2.4ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 33.4ms\n","Speed: 3.5ms preprocess, 33.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 33.6ms\n","Speed: 2.6ms preprocess, 33.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.8ms\n","Speed: 2.1ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 36.6ms\n","Speed: 2.7ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 33.6ms\n","Speed: 3.2ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.7ms\n","Speed: 2.4ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 36.0ms\n","Speed: 3.5ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.4ms\n","Speed: 2.2ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.7ms\n","Speed: 3.5ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 36.5ms\n","Speed: 2.5ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 32.8ms\n","Speed: 2.5ms preprocess, 32.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.1ms\n","Speed: 3.5ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.4ms\n","Speed: 2.6ms preprocess, 35.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.3ms\n","Speed: 2.7ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.8ms\n","Speed: 2.9ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.4ms\n","Speed: 3.0ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.1ms\n","Speed: 3.4ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.0ms\n","Speed: 2.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 37.1ms\n","Speed: 3.2ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 1 Insan, 34.3ms\n","Speed: 2.6ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.1ms\n","Speed: 2.7ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.7ms\n","Speed: 2.5ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.2ms\n","Speed: 2.2ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 33.6ms\n","Speed: 3.4ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.2ms\n","Speed: 3.7ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 32.6ms\n","Speed: 3.3ms preprocess, 32.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.8ms\n","Speed: 2.5ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 36.6ms\n","Speed: 3.6ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 33.8ms\n","Speed: 3.5ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.8ms\n","Speed: 3.5ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 36.0ms\n","Speed: 3.4ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.6ms\n","Speed: 2.7ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.8ms\n","Speed: 3.6ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.4ms\n","Speed: 2.4ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 34.6ms\n","Speed: 2.5ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 35.1ms\n","Speed: 3.6ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 35.2ms\n","Speed: 2.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 34.3ms\n","Speed: 3.6ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.0ms\n","Speed: 2.3ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.8ms\n","Speed: 2.8ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.6ms\n","Speed: 2.6ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.1ms\n","Speed: 2.6ms preprocess, 35.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.1ms\n","Speed: 2.6ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 36.2ms\n","Speed: 2.7ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 33.0ms\n","Speed: 2.3ms preprocess, 33.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.3ms\n","Speed: 2.6ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.4ms\n","Speed: 2.2ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.5ms\n","Speed: 2.2ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.7ms\n","Speed: 2.5ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.9ms\n","Speed: 3.3ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 33.8ms\n","Speed: 3.2ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 32.0ms\n","Speed: 3.2ms preprocess, 32.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.4ms\n","Speed: 3.4ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.9ms\n","Speed: 2.4ms preprocess, 34.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 36.0ms\n","Speed: 2.7ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.2ms\n","Speed: 2.1ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.4ms\n","Speed: 2.7ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.6ms\n","Speed: 3.5ms preprocess, 35.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.3ms\n","Speed: 2.3ms preprocess, 34.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.2ms\n","Speed: 2.3ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.9ms\n","Speed: 2.8ms preprocess, 34.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.2ms\n","Speed: 2.2ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.1ms\n","Speed: 3.5ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.3ms\n","Speed: 2.4ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 36.3ms\n","Speed: 2.6ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.4ms\n","Speed: 2.2ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.1ms\n","Speed: 3.2ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.5ms\n","Speed: 3.5ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.3ms\n","Speed: 3.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 33.9ms\n","Speed: 2.5ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.6ms\n","Speed: 2.4ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 33.7ms\n","Speed: 2.5ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.7ms\n","Speed: 2.8ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 36.0ms\n","Speed: 2.6ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 35.7ms\n","Speed: 3.5ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.6ms\n","Speed: 2.6ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 35.0ms\n","Speed: 2.3ms preprocess, 35.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 32.6ms\n","Speed: 2.7ms preprocess, 32.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 37.0ms\n","Speed: 2.2ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 33.7ms\n","Speed: 3.2ms preprocess, 33.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.7ms\n","Speed: 3.5ms preprocess, 34.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 36.7ms\n","Speed: 2.4ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.4ms\n","Speed: 2.4ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 33.8ms\n","Speed: 3.6ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 36.0ms\n","Speed: 2.3ms preprocess, 36.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 34.7ms\n","Speed: 2.5ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 Arabas, 33.7ms\n","Speed: 2.3ms preprocess, 33.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.7ms\n","Speed: 3.6ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 36.3ms\n","Speed: 2.6ms preprocess, 36.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.5ms\n","Speed: 2.4ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.4ms\n","Speed: 2.4ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 36.2ms\n","Speed: 2.5ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 36.5ms\n","Speed: 3.5ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.6ms\n","Speed: 3.5ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.3ms\n","Speed: 2.4ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.9ms\n","Speed: 2.1ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.1ms\n","Speed: 2.6ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.6ms\n","Speed: 2.2ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 36.1ms\n","Speed: 2.6ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.4ms\n","Speed: 2.5ms preprocess, 35.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.0ms\n","Speed: 2.3ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.4ms\n","Speed: 2.4ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.6ms\n","Speed: 2.3ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.0ms\n","Speed: 2.3ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.8ms\n","Speed: 2.3ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 33.3ms\n","Speed: 2.4ms preprocess, 33.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.2ms\n","Speed: 3.1ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 37.0ms\n","Speed: 2.8ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.9ms\n","Speed: 2.8ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 33.9ms\n","Speed: 2.6ms preprocess, 33.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.2ms\n","Speed: 3.5ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.2ms\n","Speed: 4.0ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.6ms\n","Speed: 2.4ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.4ms\n","Speed: 2.7ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.6ms\n","Speed: 2.2ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.9ms\n","Speed: 2.7ms preprocess, 34.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.9ms\n","Speed: 2.2ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.3ms\n","Speed: 2.5ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.6ms\n","Speed: 2.8ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.4ms\n","Speed: 2.4ms preprocess, 34.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 37.0ms\n","Speed: 2.3ms preprocess, 37.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.6ms\n","Speed: 2.4ms preprocess, 34.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.6ms\n","Speed: 2.4ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.5ms\n","Speed: 2.7ms preprocess, 35.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.5ms\n","Speed: 2.7ms preprocess, 34.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.9ms\n","Speed: 2.2ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.5ms\n","Speed: 3.1ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.7ms\n","Speed: 2.5ms preprocess, 35.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.4ms\n","Speed: 3.4ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 33.8ms\n","Speed: 2.7ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 31.5ms\n","Speed: 2.4ms preprocess, 31.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.7ms\n","Speed: 2.3ms preprocess, 34.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.5ms\n","Speed: 2.6ms preprocess, 34.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.3ms\n","Speed: 2.5ms preprocess, 35.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 37.1ms\n","Speed: 2.4ms preprocess, 37.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.9ms\n","Speed: 3.4ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 33.8ms\n","Speed: 3.4ms preprocess, 33.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.4ms\n","Speed: 3.2ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.1ms\n","Speed: 2.4ms preprocess, 34.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.6ms\n","Speed: 2.3ms preprocess, 34.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 36.9ms\n","Speed: 2.6ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.8ms\n","Speed: 3.7ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.7ms\n","Speed: 2.5ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 36.9ms\n","Speed: 2.2ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 33.3ms\n","Speed: 2.1ms preprocess, 33.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.3ms\n","Speed: 2.4ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.1ms\n","Speed: 2.7ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.5ms\n","Speed: 3.6ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 33.7ms\n","Speed: 3.5ms preprocess, 33.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.6ms\n","Speed: 2.6ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 37.1ms\n","Speed: 3.3ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.7ms\n","Speed: 3.0ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.2ms\n","Speed: 2.6ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.2ms\n","Speed: 3.2ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.2ms\n","Speed: 2.2ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.7ms\n","Speed: 2.5ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 36.7ms\n","Speed: 3.7ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 32.7ms\n","Speed: 2.9ms preprocess, 32.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 35.0ms\n","Speed: 2.4ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.5ms\n","Speed: 3.2ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.9ms\n","Speed: 2.5ms preprocess, 34.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 35.0ms\n","Speed: 3.5ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.9ms\n","Speed: 2.8ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.4ms\n","Speed: 2.4ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.8ms\n","Speed: 2.8ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 36.6ms\n","Speed: 3.7ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 Arabas, 34.4ms\n","Speed: 2.4ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.8ms\n","Speed: 2.3ms preprocess, 34.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.4ms\n","Speed: 2.3ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.5ms\n","Speed: 2.8ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.6ms\n","Speed: 2.7ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.3ms\n","Speed: 2.4ms preprocess, 35.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 37.0ms\n","Speed: 2.5ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.1ms\n","Speed: 2.5ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.4ms\n","Speed: 2.4ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.6ms\n","Speed: 2.7ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 36.1ms\n","Speed: 2.4ms preprocess, 36.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.6ms\n","Speed: 2.3ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 35.0ms\n","Speed: 3.6ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 33.6ms\n","Speed: 3.2ms preprocess, 33.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.7ms\n","Speed: 3.5ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 37.2ms\n","Speed: 3.3ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.1ms\n","Speed: 2.7ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.7ms\n","Speed: 2.8ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.7ms\n","Speed: 2.4ms preprocess, 35.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 33.0ms\n","Speed: 2.7ms preprocess, 33.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.1ms\n","Speed: 3.4ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 36.4ms\n","Speed: 2.1ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.4ms\n","Speed: 2.6ms preprocess, 34.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.8ms\n","Speed: 2.4ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 36.3ms\n","Speed: 2.7ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 32.8ms\n","Speed: 3.5ms preprocess, 32.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 33.9ms\n","Speed: 3.4ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.3ms\n","Speed: 2.2ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 37.2ms\n","Speed: 3.1ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 33.8ms\n","Speed: 2.4ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.3ms\n","Speed: 2.2ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 36.0ms\n","Speed: 2.5ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.7ms\n","Speed: 3.4ms preprocess, 35.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 34.3ms\n","Speed: 2.2ms preprocess, 34.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.2ms\n","Speed: 2.8ms preprocess, 35.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 36.4ms\n","Speed: 2.0ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 Arabas, 34.2ms\n","Speed: 2.4ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 35.3ms\n","Speed: 2.4ms preprocess, 35.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 37.7ms\n","Speed: 2.3ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.7ms\n","Speed: 2.5ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 Arabas, 35.2ms\n","Speed: 2.2ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 36.5ms\n","Speed: 2.2ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 36.7ms\n","Speed: 2.8ms preprocess, 36.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 Arabas, 34.7ms\n","Speed: 2.3ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 Arabas, 34.8ms\n","Speed: 3.4ms preprocess, 34.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 Arabas, 37.0ms\n","Speed: 2.6ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:root:Video bitti veya frame okunamadı.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ssTtRYLtPzkk","executionInfo":{"status":"ok","timestamp":1739214264489,"user_tz":-180,"elapsed":21843,"user":{"displayName":"Yusuf Doğu","userId":"04280726024577573353"}},"outputId":"1d0e60db-93d5-40ba-d35f-a9ea98e0d31c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}]}